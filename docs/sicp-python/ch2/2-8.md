# 2.8 效率

:::info
译者：[Mancuoj](https://github.com/mancuoj)

来源：[2.8 Efficiency](http://composingprograms.com/pages/28-efficiency.html)

对应：无

:::details 声明

叠甲过：本翻译纯属个人爱好，如果涉及到任何版权行为，请联系我，我将删除内容。文中所有内容，与本人现在，之前或者将来的雇佣公司无关，本人保留自省的权利，也就是说你看到的内容不一定代表本人最新的认知和观点。

关于版权：本系列所有文章除特别声明外，均采用 [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh) 许可协议，转载请注明来自 [csfive](https://github.com/csfive)！

另外，如果：

- 你发现了翻译的错漏，可以向关联的 [GitHub 仓库](https://github.com/csfive/docs) 提交 issue 或者 PR
- 你觉得我做的还不错，可以关注 [本组织](https://github.com/csfive) 或 [本人](https://github.com/mancuoj)，并给关联仓库一个 star ⭐
- 你也想加入本组织一起学习或有一些其他方面的问题，可以点击右上角图标加入本组织的 Discord
- ...
:::


Decisions of how to represent and process data are often influenced by the efficiency of alternatives. Efficiency refers to the computational resources used by a representation or process, such as how much time and memory are required to compute the result of a function or represent an object. These amounts can vary widely depending on the details of an implementation.

关于如何表示和处理数据的决定往往受到替代办法效率的影响。效率指的是表示或过程所使用的计算资源，例如计算函数的结果或表示对象需要多少时间和内存。这些量可以根据实施方式的细节而广泛地变化。

## 2.8.1  Measuring Efficiency 2.8.1 测量效率

Measuring exactly how long a program requires to run or how much memory it consumes is challenging, because the results depend upon many details of how a computer is configured. A more reliable way to characterize the efficiency of a program is to measure how many times some event occurs, such as a function call.

精确测量一个程序需要运行多长时间或消耗多少内存是一项挑战，因为结果取决于计算机配置的许多细节。描述程序效率的一个更可靠的方法是测量某个事件发生的次数，比如函数调用。

Let's return to our first tree-recursive function, the `fib` function for computing numbers in the Fibonacci sequence.

让我们回到第一个树递归函数， `fib` 函数用于计算斐波那契数列中的数字。

```py
>>> def fib(n):
        if n == 0:
            return 0
        if n == 1:
            return 1
        return fib(n-2) + fib(n-1)
>>> fib(5)
5
```

Consider the pattern of computation that results from evaluating `fib(6)`, depicted below. To compute `fib(5)`, we compute `fib(3)` and `fib(4)`. To compute `fib(3)`, we compute `fib(1)` and `fib(2)`. In general, the evolved process looks like a tree. Each blue dot indicates a completed computation of a Fibonacci number in the traversal of this tree.

考虑计算 `fib(6)` 所产生的计算模式，如下所示。为了计算 `fib(5)` ，我们计算 `fib(3)` 和 `fib(4)` 。为了计算 `fib(3)` ，我们计算 `fib(1)` 和 `fib(2)` 。一般来说，演化过程看起来像一棵树。每个蓝点表示在遍历此树时完成了斐波那契数的计算。

![fib](/sicp-python/fib.png)

This function is instructive as a prototypical tree recursion, but it is a terribly inefficient way to compute Fibonacci numbers because it does so much redundant computation. The entire computation of `fib(3)` is duplicated.

这个函数作为一个典型的树递归是有指导意义的，但是它是一个非常低效的计算斐波那契数的方法，因为它做了太多的冗余计算。重复 `fib(3)` 的整个计算。

We can measure this inefficiency. The higher-order `count` function returns an equivalent function to its argument that also maintains a `call_count` attribute. In this way, we can inspect just how many times `fib` is called.

我们可以衡量这种低效率。高阶 `count` 函数返回与其参数等效的函数，该函数也维护 `call_count` 属性。通过这种方式，我们可以检查 `fib` 被调用了多少次。

```py
>>> def count(f):
        def counted(*args):
            counted.call_count += 1
            return f(*args)
        counted.call_count = 0
        return counted
```

By counting the number of calls to `fib`, we see that the calls required grows faster than the Fibonacci numbers themselves. This rapid expansion of calls is characteristic of tree-recursive functions.

通过计算对 `fib` 的调用次数，我们看到所需的调用次数比斐波那契数列本身增长得更快。这种调用的快速扩展是树递归函数的特征。

```py
>>> fib = count(fib)
>>> fib(19)
4181
>>> fib.call_count
13529
```

**Space.** To understand the space requirements of a function, we must specify generally how memory is used, preserved, and reclaimed in our environment model of computation. In evaluating an expression, the interpreter preserves all *active* environments and all values and frames referenced by those environments. An environment is active if it provides the evaluation context for some expression being evaluated. An environment becomes inactive whenever the function call for which its first frame was created finally returns.

空间。为了理解一个函数的空间需求，我们必须详细说明在我们的计算环境模型中内存是如何使用、保留和回收的。在计算表达式时，解释器保留所有活动环境以及这些环境引用的所有值和帧。如果环境为某个正在计算的表达式提供计算上下文，则该环境是活动的。每当为其创建第一帧的函数调用最终返回时，环境变为非活动状态。

For example, when evaluating `fib`, the interpreter proceeds to compute each value in the order shown previously, traversing the structure of the tree. To do so, it only needs to keep track of those nodes that are above the current node in the tree at any point in the computation. The memory used to evaluate the rest of the branches can be reclaimed because it cannot affect future computation. In general, the space required for tree-recursive functions will be proportional to the maximum depth of the tree.

例如，当计算 `fib` 时，解释器继续按照前面所示的顺序计算每个值，遍历树的结构。要做到这一点，它只需要跟踪在计算中的任何点上树中当前节点之上的那些节点。用于计算其余分支的内存可以回收，因为它不会影响将来的计算。一般来说，树递归函数所需的空间与树的最大深度成正比。

The diagram below depicts the environment created by evaluating `fib(3)`. In the process of evaluating the return expression for the initial application of `fib`, the expression `fib(n-2)` is evaluated, yielding a value of 0. Once this value is computed, the corresponding environment frame (grayed out) is no longer needed: it is not part of an active environment. Thus, a well-designed interpreter can reclaim the memory that was used to store this frame. On the other hand, if the interpreter is currently evaluating `fib(n-1)`, then the environment created by this application of `fib` (in which `n` is 2) is active. In turn, the environment originally created to apply `fib` to 3 is active because its return value has not yet been computed.

下图描述了通过评估 `fib(3)` 创建的环境。在对用于 `fib` 的初始应用的返回表达式求值的处理中，表达式 `fib(n-2)` 被求值，产生值0。计算该值后，将不再需要相应的环境帧（灰显）：它不是活动环境一部分。因此，设计良好的解释器可以回收用于存储此帧的内存。另一方面，如果解释程序正在评估 `fib(n-1)` ，则由 `fib` （其中 `n` 是2）的该应用创建的环境是活动的。反过来，最初为将 `fib` 应用于3而创建的环境是活动的，因为其返回值还没有被计算。

The higher-order `count_frames` function tracks `open_count`, the number of calls to the function `f` that have not yet returned. The `max_count` attribute is the maximum value ever attained by `open_count`, and it corresponds to the maximum number of frames that are ever simultaneously active during the course of computation.

高阶 `count_frames` 函数跟踪 `open_count` ，即尚未返回的对函数 `f` 的调用的数目。 `max_count` 属性是 `open_count` 曾经达到的最大值，并且它对应于在计算过程期间曾经同时活动的帧的最大数目。

```py
>>> def count_frames(f):
        def counted(*args):
            counted.open_count += 1
            counted.max_count = max(counted.max_count, counted.open_count)
            result = f(*args)
            counted.open_count -= 1
            return result
        counted.open_count = 0
        counted.max_count = 0
        return counted
>>> fib = count_frames(fib)
>>> fib(19)
4181
>>> fib.open_count
0
>>> fib.max_count
19
>>> fib(24)
46368
>>> fib.max_count
24
```

To summarize, the space requirement of the `fib` function, measured in active frames, is one less than the input, which tends to be small. The time requirement measured in total recursive calls is larger than the output, which tends to be huge.

总而言之， `fib` 函数的空间需求（在活动帧中测量）比输入少一个，输入往往很小。总递归调用所需的时间大于输出，后者往往很大。

## 2.8.2  Memoization 2.8.2 回忆

Tree-recursive computational processes can often be made more efficient through *memoization*, a powerful technique for increasing the efficiency of recursive functions that repeat computation. A memoized function will store the return value for any arguments it has previously received. A second call to `fib(25)` would not re-compute the return value recursively, but instead return the existing one that has already been constructed.

树递归的计算过程通常可以通过记忆来提高效率，记忆是一种强大的技术，可以提高重复计算的递归函数的效率。记忆函数将存储它以前接收到的任何参数的返回值。对 `fib(25)` 的第二次调用不会递归地重新计算返回值，而是返回已经构造的现有值。

Memoization can be expressed naturally as a higher-order function, which can also be used as a decorator. The definition below creates a *cache* of previously computed results, indexed by the arguments from which they were computed. The use of a dictionary requires that the argument to the memoized function be immutable.

记忆化可以自然地表示为高阶函数，它也可以用作装饰器。下面的定义创建了以前计算结果的缓存，这些结果由计算它们的参数索引。字典的使用要求记忆函数的参数是不可变的。

```py
>>> def memo(f):
        cache = {}
        def memoized(n):
            if n not in cache:
                cache[n] = f(n)
            return cache[n]
        return memoized
```

If we apply `memo` to the recursive computation of Fibonacci numbers, a new pattern of computation evolves, depicted below.

如果我们将 `memo` 应用于斐波那契数的递归计算，则会演化出一种新的计算模式，如下所示。

![fib_memo](/sicp-python/fib_memo.png)

In this computation of `fib(5)`, the results for `fib(2)` and `fib(3)` are reused when computing `fib(4)` on the right branch of the tree. As a result, much of the tree-recursive computation is not required at all.

在该 `fib(5)` 的计算中，当在树的右分支上计算 `fib(4)` 时，重用 `fib(2)` 和 `fib(3)` 的结果。因此，根本不需要很多树递归计算。

Using `count`, we can see that the `fib` function is actually only called once for each unique input to `fib`.

使用 `count` ，我们可以看到，对于 `fib` 的每个唯一输入， `fib` 函数实际上只被调用一次。

```py
>>> counted_fib = count(fib)
>>> fib  = memo(counted_fib)
>>> fib(19)
4181
>>> counted_fib.call_count
20
>>> fib(34)
5702887
>>> counted_fib.call_count
35
```

## 2.8.3  Orders of Growth 2.8.3 生长顺序

Processes can differ massively in the rates at which they consume the computational resources of space and time, as the previous examples illustrate. However, exactly determining just how much space or time will be used when calling a function is a very difficult task that depends upon many factors. A useful way to analyze a process is to categorize it along with a group of processes that all have similar requirements. A useful categorization is the *order of growth* of a process, which expresses in simple terms how the resource requirements of a process grow as a function of the input.

正如前面的示例所示，进程消耗空间和时间计算资源的速率可能有很大不同。然而，准确地确定调用函数时将使用多少空间或时间是一项非常困难的任务，它取决于许多因素。分析流程的一种有用方法是将其与一组具有相似需求的流程沿着进行分类。一个有用的分类是流程的增长顺序，它用简单的术语表示流程的资源需求如何作为输入的函数增长。

As an introduction to orders of growth, we will analyze the function `count_factors` below, which counts the number of integers that evenly divide an input `n`. The function attempts to divide `n` by every integer less than or equal to its square root. The implementation takes advantage of the fact that if k� divides n� and k<n−−√�<� , then there is another factor j=n/k�=�/� such that j>n−−√�>�. 

作为对增长阶数的介绍，我们将分析下面的函数 `count_factors` ，该函数计算将输入 `n` 整除的整数的个数。此函数尝试将 `n` 除以每个小于或等于其平方根的整数。该实现利用了这样一个事实，即如果k𝑘整除n𝑛且k〈n − − √𝑘〈𝑛，则存在另一个因子j=n/k𝑗=𝑛/，𝑘使得j〉n − − √𝑗〉𝑛。

How much time is required to evaluate `count_factors`? The exact answer will vary on different machines, but we can make some useful general observations about the amount of computation involved. The total number of times this process executes the body of the `while` statement is the greatest integer less than n−−√�. The statements before and after this `while` statement are executed exactly once. So, the total number of statements executed is w⋅n−−√+v�⋅�+�, where w� is the number of statements in the `while` body and v� is the number of statements outside of the `while` statement. Although it isn't exact, this formula generally characterizes how much time will be required to evaluate `count_factors` as a function of the input `n`.

评估 `count_factors` 需要多长时间？确切的答案在不同的机器上会有所不同，但我们可以对所涉及的计算量做一些有用的一般性观察。这个进程执行 `while` 语句主体的总次数是小于n − − √的最大整数𝑛。此 `while` 语句前后的语句只执行一次。因此，执行的语句总数为w⋅ n − − √ +v𝑤⋅𝑛+𝑣，其中w𝑤是 `while` 语句体中的语句数，v𝑣是 `while` 语句之外的语句数。尽管不精确，但该公式通常表征了将需要多少时间来评估作为输入 `n` 的函数的 `count_factors` 。

A more exact description is difficult to obtain. The constants w� and v� are not constant at all, because the assignment statements to `factors` are sometimes executed but sometimes not. An order of growth analysis allows us to gloss over such details and instead focus on the general shape of growth. In particular, the order of growth for `count_factors` expresses in precise terms that the amount of time required to compute `count_factors(n)` scales at the rate n−−√�, within a margin of some constant factors.

很难得到更精确的描述。常数w𝑤和v𝑣根本不是常数，因为对 `factors` 的赋值语句有时执行，有时不执行。一个增长分析的顺序允许我们掩盖这些细节，而把注意力集中在增长的总体形状上。特别地， `count_factors` 的增长顺序用精确的术语表示了计算 `count_factors(n)` 所需的时间量以n − − √的速率增长𝑛，在一些常数因子的裕度内。

**Theta Notation.** Let n� be a parameter that measures the size of the input to some process, and let R(n)�(�) be the amount of some resource that the process requires for an input of size n�. In our previous examples we took n� to be the number for which a given function is to be computed, but there are other possibilities. For instance, if our goal is to compute an approximation to the square root of a number, we might take n� to be the number of digits of accuracy required.

Theta符号。设n𝑛是度量某个进程的输入大小的参数，R（n）𝑅（𝑛）是该进程对于大小为n的输入所需的某个资源的量𝑛。在前面的例子中，我们取n𝑛为要计算的给定函数的个数，但也有其他可能性。例如，如果我们的目标是计算一个数的平方根的近似值，我们可以取n𝑛作为所需精度的位数。

R(n)�(�) might measure the amount of memory used, the number of elementary machine steps performed, and so on. In computers that do only a fixed number of steps at a time, the time required to evaluate an expression will be proportional to the number of elementary steps performed in the process of evaluation.
R（n）𝑅（英文）𝑛）可以测量使用的内存量、执行的基本机器步骤数等。在一次只执行固定步骤数的计算机中，计算表达式所需的时间将与计算过程中执行的基本步骤数成正比。

We say that R(n)�(�) has order of growth Θ(f(n))Θ(�(�)), written R(n)=Θ(f(n))�(�)=Θ(�(�)) (pronounced "theta of f(n)�(�)"), if there are positive constants k1�1 and k2�2 independent of n� such that

我们说R（n）𝑅（英文）𝑛）的增长顺序为Θ（f（n））Θ（𝑓（英文）𝑛）），记作R（n）=Θ（f（n））𝑅（英文）𝑛）= Θ（𝑓（英文）𝑛））（读作“f（n）的θ𝑓（英文）𝑛）”），如果存在正常数k 1𝑘1和k 2𝑘2独立于n𝑛使得

k1⋅f(n)≤R(n)≤k2⋅f(n)�1⋅�(�)≤�(�)≤�2⋅�(�)
k 1 ⋅ f（n）≤ R（n）≤ k 2 ⋅ f（n）𝑘1 ⋅𝑓）（𝑛）≤𝑅）（𝑛）≤𝑘2 ⋅𝑓）（𝑛）

for any value of n� larger than some minimum m�. In other words, for large n�, the value R(n)�(�) is always sandwiched between two values that both scale with f(n)�(�):

对于任意n值𝑛大于某个最小值m𝑚。换句话说，对于较大的n𝑛，值R（n）𝑅（英文）𝑛）总是夹在两个都随f（n）缩放的值之间𝑓（英文）𝑛）：

- A lower bound k1⋅f(n)�1⋅�(�) and
- k ~ 1 ⋅f（n）的一个下界𝑘1𝑓（英文）𝑛）及
- An upper bound k2⋅f(n)�2⋅�(�)
- k ~ 2 ⋅f（n）的上界𝑘2𝑓（英文）𝑛）

We can apply this definition to show that the number of steps required to evaluate `count_factors(n)` grows as Θ(n−−√)Θ(�) by inspecting the function body.

我们可以应用这个定义来证明计算 `count_factors(n)` 所需的步骤数随Θ（n − − √）Θ（𝑛）通过检查函数体。

First, we choose k1=1�1=1 and m=0�=0, so that the lower bound states that `count_factors(n)` requires at least 1⋅n−−√1⋅� steps for any n>0�>0. There are at least 4 lines executed outside of the `while` statement, each of which takes at least 1 step to execute. There are at least two lines executed within the `while` body, along with the while header itself. All of these require at least one step. The `while` body is evaluated at least n−−√−1�−1 times. Composing these lower bounds, we see that the process requires at least 4+3⋅(n−−√−1)4+3⋅(�−1) steps, which is always larger than k1⋅n−−√�1⋅�.

首先，我们选择k1 =1𝑘1 = 1且m=0𝑚= 0，因此下限表明 `count_factors(n)` 至少需要1⋅ n − − √ 1 ⋅𝑛任意n〉0的步长𝑛〉0。在 `while` 语句之外至少执行了4行，每一行至少需要1个步骤来执行。在 `while` 主体中至少执行了两行代码，沿着while头本身。所有这些都需要至少一个步骤。 `while` 主体至少评估n − − √ −1𝑛-1倍。把这些下界组合起来，我们看到这个过程至少需要4+3⋅（n − − √ −1）4 + 3 ⋅（𝑛− 1）步数，它总是大于k 1 ⋅ n − − √𝑘1𝑛。

Second, we can verify the upper bound. We assume that any single line in the body of `count_factors` requires at most `p` steps. This assumption isn't true for every line of Python, but does hold in this case. Then, evaluating `count_factors(n)` can require at most p⋅(5+4n−−√)�⋅(5+4�), because there are 5 lines outside of the `while` statement and 4 within (including the header). This upper bound holds even if every `if` header evaluates to true. Finally, if we choose k2=5p�2=5�, then the steps required is always smaller than k2⋅n−−√�2⋅�. Our argument is complete.

第二，我们可以验证上界。我们假设 `count_factors` 主体中的任何一行最多需要 `p` 步。这个假设并不是对Python的每一行都成立，但在本例中成立。那么，计算 `count_factors(n)` 最多需要p·（5+4 n − − √）𝑝·（5 + 4𝑛），因为 `while` 语句外面有5行，里面有4行（包括标题）。即使每个 `if` 标头的值都为true，这个上限也成立。最后，如果我们选择k 2 =5p𝑘2 = 5𝑝，那么所需的步数总是小于k 2 ⋅ n − − √𝑘2 ⋅𝑛。我们的论点已经结束了。

## 2.8.4  Example: Exponentiation 2.8.4 示例：指数运算

Consider the problem of computing the exponential of a given number. We would like a function that takes as arguments a base `b` and a positive integer exponent `n` and computes bn��. One way to do this is via the recursive definition

考虑计算给定数的指数的问题。我们希望有一个函数，它的参数是一个基数 `b` 和一个正整数指数 `n` ，并计算b n𝑏𝑛。一种方法是通过递归定义

bnb0=b⋅bn−1=1��=�⋅��−1�0=1

b nb 0=bb n-1=1𝑏𝑛 =𝑏在𝑏𝑛第1步 𝑏 0 =1

which translates readily into the recursive function

它很容易转换成递归函数

```py
>>> def exp(b, n):
        if n == 0:
            return 1
        return b * exp(b, n-1)
```

This is a linear recursive process that requires Θ(n)Θ(�) steps and Θ(n)Θ(�) space. Just as with factorial, we can readily formulate an equivalent linear iteration that requires a similar number of steps but constant space.

这是一个线性递归过程，需要Θ（n）Θ（𝑛）步和Θ（n）Θ（𝑛）空间。就像阶乘一样，我们可以很容易地用公式表示一个等价的线性迭代，它需要相似的步骤数，但空间不变。

```py
>>> def exp_iter(b, n):
        result = 1
        for _ in range(n):
            result = result * b
        return result
```

We can compute exponentials in fewer steps by using successive squaring. For instance, rather than computing b8�8 as

通过使用连续平方，我们可以用更少的步骤计算指数。例如，计算B𝑏时，

b⋅(b⋅(b⋅(b⋅(b⋅(b⋅(b⋅b))))))�⋅(�⋅(�⋅(�⋅(�⋅(�⋅(�⋅�))))))

we can compute it using three multiplications: 

我们可以使用三个乘法来计算它：

b2b4b8=b⋅b=b2⋅b2=b4⋅b4�2=�⋅��4=�2⋅�2�8=�4⋅�4

This method works fine for exponents that are powers of 2. We can also take advantage of successive squaring in computing exponentials in general if we use the recursive rule

此方法适用于2的幂的指数。如果我们使用递归规则，我们通常也可以在计算指数时利用连续平方

bn={(b12n)2b⋅bn−1if n is evenif n is odd��={(�12�)2if � is even�⋅��−1if � is odd



We can express this method as a recursive function as well: 

我们也可以将此方法表示为递归函数：

```py
>>> def square(x):
        return x*x
>>> def fast_exp(b, n):
        if n == 0:
            return 1
        if n % 2 == 0:
            return square(fast_exp(b, n//2))
        else:
            return b * fast_exp(b, n-1)
>>> fast_exp(2, 100)
1267650600228229401496703205376
```

The process evolved by `fast_exp` grows logarithmically with `n` in both space and number of steps. To see this, observe that computing b2n�2� using `fast_exp` requires only one more multiplication than computing bn��. The size of the exponent we can compute therefore doubles (approximately) with every new multiplication we are allowed. Thus, the number of multiplications required for an exponent of `n` grows about as fast as the logarithm of `n` base 2. The process has Θ(logn)Θ(log⁡�) growth. The difference between Θ(logn)Θ(log⁡�) growth and Θ(n)Θ(�) growth becomes striking as n� becomes large. For example, `fast_exp` for `n` of 1000 requires only 14 multiplications instead of 1000.

由 `fast_exp` 演化的过程在空间和步骤数上都与 `n` 成对数增长。要了解这一点，请注意使用 `fast_exp` 计算b 2n𝑏2𝑛只需要比计算b n多一次乘法𝑏𝑛。因此，我们可以计算的指数的大小随着我们允许的每一次新乘法而（近似地）翻倍。因此， `n` 的指数所需的乘法次数增长得大约与以2为底的 `n` 的对数一样快。该过程具有Θ（logn）Θ（log𝑛）增长。当n变大时，Θ（logn）Θ（log𝑛）增长率和Θ（n）Θ（𝑛）增长率之间的差异变得非常显著𝑛。例如，对于1000的 `n` ， `fast_exp` 仅需要14次乘法而不是1000次。

## 2.8.5  Growth Categories  2.8.5 增长类别

Orders of growth are designed to simplify the analysis and comparison of computational processes. Many different processes can all have equivalent orders of growth, which indicates that they scale in similar ways. It is an essential skill of a computer scientist to know and recognize common orders of growth and identify processes of the same order.

增长顺序的设计是为了简化计算过程的分析和比较。许多不同的过程都有相同的增长顺序，这表明它们以相似的方式扩展。了解和识别常见的增长顺序并识别相同顺序的过程是计算机科学家的一项基本技能。

**Constants.** Constant terms do not affect the order of growth of a process. So, for instance, Θ(n)Θ(�) and Θ(500⋅n)Θ(500⋅�) are the same order of growth. This property follows from the definition of theta notation, which allows us to choose arbitrary constants k1�1 and k2�2 (such as 15001500) for the upper and lower bounds. For simplicity, constants are always omitted from orders of growth.

常数。常数项不影响过程的增长阶。因此，例如Θ（n）Θ（𝑛）和Θ（500⋅n）Θ（500 ⋅𝑛）是相同的增长顺序。这个性质是从θ符号的定义得出的，它允许我们选择任意常数k 1𝑘1和k 2𝑘2（如1 500 1 500）作为上界和下界。为简单起见，增长顺序中总是省略常数。

**Logarithms.** The base of a logarithm does not affect the order of growth of a process. For instance, log2nlog2⁡� and log10nlog10⁡� are the same order of growth. Changing the base of a logarithm is equivalent to multiplying by a constant factor.

对数。对数的底不影响进程的增长阶。例如，log 2 n log 2𝑛和log 10 n log 10𝑛是相同的增长顺序。更改对数的底数等效于乘以常数因子。

**Nesting.** When an inner computational process is repeated for each step in an outer process, then the order of growth of the entire process is a product of the number of steps in the outer and inner processes.

筑巢。当一个内部计算过程在一个外部过程中的每一步都被重复时，那么整个过程的增长顺序是外部和内部过程中的步骤数的乘积。

For example, the function `overlap` below computes the number of elements in list `a` that also appear in list `b`.

例如，下面的函数 `overlap` 计算列表 `a` 中同时出现在列表 `b` 中的元素数。

```py
>>> def overlap(a, b):
        count = 0
        for item in a:
            if item in b:
                count += 1
        return count
    
>>> overlap([1, 3, 2, 2, 5, 1], [5, 4, 2])
3
```

The `in` operator for lists requires Θ(n)Θ(�) time, where n� is the length of the list `b`. It is applied Θ(m)Θ(�) times, where m� is the length of the list `a`. The `item in b` expression is the inner process, and the `for item in a` loop is the outer process. The total order of growth for this function is Θ(m⋅n)Θ(�⋅�).

列表的 `in` 运算符需要Θ（n）Θ（𝑛）时间，其中n𝑛是列表 `b` 的长度。它被应用Θ（m）Θ（𝑚）次，其中m𝑚是列表 `a` 的长度。 `item in b` 表达式是内部进程， `for item in a` 循环是外部进程。这个函数的总增长阶为Θ（m⋅n）Θ（𝑚⋅𝑛）。

**Lower-order terms.** As the input to a process grows, the fastest growing part of a computation dominates the total resources used. Theta notation captures this intuition. In a sum, all but the fastest growing term can be dropped without changing the order of growth.

低阶项。随着进程输入的增长，计算中增长最快的部分支配着所使用的总资源。Theta符号表达了这种直觉。总之，除了增长最快的项之外，所有项都可以去掉，而不改变增长的顺序。

For instance, consider the `one_more` function that returns how many elements of a list `a` are one more than some other element of `a`. That is, in the list `[3, 14, 15, 9]`, the element 15 is one more than 14, so `one_more` will return 1.

例如，考虑 `one_more` 函数，它返回列表 `a` 中有多少个元素比列表 `a` 中的其他元素多1。也就是说，在列表 `[3, 14, 15, 9]` 中，元素15比14大1，因此 `one_more` 将返回1。

```py
>>> def one_more(a):
        return overlap([x-1 for x in a], a)
>>> one_more([3, 14, 15, 9])
1
```

There are two parts to this computation: the list comprehension and the call to `overlap`. For a list `a` of length n�, list comprehension requires Θ(n)Θ(�) steps, while the call to `overlap` requires Θ(n2)Θ(�2) steps. The sum of steps is Θ(n+n2)Θ(�+�2), but this is not the simplest way of expressing the order of growth.

此计算有两个部分：列表解析和对 `overlap` 的调用。对于长度为n的列表 `a` 𝑛，列表解析需要Θ（n）Θ（𝑛）步，而对 `overlap` 的调用需要Θ（n 2）Θ（𝑛2）步。步数之和为Θ（n+ n 2）Θ（𝑛+𝑛2），但这并不是表示增长顺序的最简单方式。

Θ(n2+k⋅n)Θ(�2+�⋅�) and Θ(n2)Θ(�2) are equivalent for any constant k� because the n2�2 term will eventually dominate the total for any k�. The fact that bounds must hold only for n� greater than some minimum m� establishes this equivalence. For simplicity, lower-order terms are always omitted from orders of growth, and so we will never see a sum within a theta expression.

Θ（n2 +k⋅n）Θ（𝑛2 +𝑘⋅𝑛）和Θ（n2）Θ（𝑛2）对任何常数k都是等价的，𝑘因为n22𝑛项最终会支配任何k的总和𝑘。边界必须仅对𝑛大于某个最小值m的n成立的事实𝑚建立了这种等价性。为了简单起见，低阶项总是从增长的阶中省略，因此我们永远不会在theta表达式中看到和。

**Common categories.** Given these equivalence properties, a small set of common categories emerge to describe most computational processes. The most common are listed below from slowest to fastest growth, along with descriptions of the growth as the input increases. Examples for each category follow.

常见类别。考虑到这些等价性，出现了一小组共同的范畴来描述大多数计算过程。下面按增长速度从慢到快的顺序列出了最常见的增长方式，沿着描述了随着投入的增加而增长的情况。每个类别的示例如下。

| **Category 类别** | **Theta Notation Theta符号** | **Growth Description 生长描述**                            | **Example** |
| :---------------- | :--------------------------- | :--------------------------------------------------------- | :---------- |
| Constant 常数     | Θ(1)Θ(1)                     | Growth is independent of the input 增长与投入无关          | `abs`       |
| Logarithmic 对数  | Θ(logn)Θ(log⁡�)               | Multiplying input increments resources 投入倍增增加资源    | `fast_exp`  |
| Linear            | Θ(n)Θ(�)                     | Incrementing input increments resources 增加投入增加资源   | `exp`       |
| Quadratic 二次    | Θ(n2)Θ(�2)                   | Incrementing input adds n resources 递增输入会增加n个资源  | `one_more`  |
| Exponential 指数  | Θ(bn)Θ(��)                   | Incrementing input multiplies resources 增加投入会增加资源 | `fib`       |

Other categories exist, such as the Θ(n−−√)Θ(�) growth of `count_factors`. However, these categories are particularly common.

还有其他的分类，例如 `count_factors` 的Θ（n − − √）Θ（𝑛）增长。然而，这些类别特别常见。

Exponential growth describes many different orders of growth, because changing the base b� does affect the order of growth. For instance, the number of steps in our tree-recursive Fibonacci computation `fib` grows exponentially in its input n�. In particular, one can show that the nth Fibonacci number is the closest integer to

指数增长描述了许多不同的增长顺序，因为改变基数b𝑏确实会影响增长顺序。例如，在我们的树递归斐波那契计算 `fib` 中，步数在其输入n中呈指数增长𝑛。特别地，我们可以证明第n个斐波那契数是最接近的整数

ϕn−25–√��−25
n−2 5 - √𝜙𝑛− 2 5

where ϕ� is the golden ratio:

其中𝜙是黄金分割率：

ϕ=1+5–√2≈1.6180�=1+52≈1.6180
= 1+ 5 - √ 2 ≈1.6180𝜙= 1 + 5 2 ≈ 1.6180

We also stated that the number of steps scales with the resulting value, and so the tree-recursive process requires Θ(ϕn)Θ(��) steps, a function that grows exponentially with n�.

我们还指出，步数与结果值成比例，因此树递归过程需要Θ（n）Θ（𝜙𝑛）步，这是一个随n指数增长的函数𝑛。